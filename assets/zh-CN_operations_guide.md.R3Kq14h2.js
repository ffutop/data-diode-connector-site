import{_ as e,c as a,o,a6 as r}from"./chunks/framework.Cpr3xyXy.js";const f=JSON.parse('{"title":"网闸连接器运维指南 - 部署、监控与故障排查","description":"网闸连接器 (DDC) 生产环境部署、监控与故障排查实用指南。涵盖部署清单、关键监控指标 (StatsD)、常见问题定位及解决方案。","frontmatter":{"title":"网闸连接器运维指南 - 部署、监控与故障排查","description":"网闸连接器 (DDC) 生产环境部署、监控与故障排查实用指南。涵盖部署清单、关键监控指标 (StatsD)、常见问题定位及解决方案。","head":[["meta",{"name":"keywords","content":"网闸运维, DDC部署, 生产环境监控, 故障排查, StatsD指标, 数据丢包, Kafka重平衡, DDC运维"}]],"seo":{"proficiencyLevel":"Expert","keywords":["Operations Guide","Monitoring","Troubleshooting","Data Diode","Kafka Operations","Metrics"]}},"headers":[],"relativePath":"zh-CN/operations_guide.md","filePath":"zh-CN/operations_guide.md","lastUpdated":1764595667000}'),l={name:"zh-CN/operations_guide.md"};function s(n,t,i,d,c,h){return o(),a("div",null,[...t[0]||(t[0]=[r('<h1 id="运维指南" tabindex="-1">运维指南 <a class="header-anchor" href="#运维指南" aria-label="Permalink to “运维指南”">​</a></h1><p>本文档提供在<strong>生产环境</strong>中<strong>部署、监控和排查网闸连接器 (DDC) 故障</strong>的指南。</p><h2 id="部署检查清单-checklist" tabindex="-1">部署检查清单 (Checklist) <a class="header-anchor" href="#部署检查清单-checklist" aria-label="Permalink to “部署检查清单 (Checklist)”">​</a></h2><p>在上线之前，请确保以下几点：</p><ol><li><strong>网络连通性</strong>： <ul><li><strong>入口代理</strong>：可以连接到源（如 Kafka）和网闸硬件/网络接口。</li><li><strong>出口代理</strong>：可以连接到网闸硬件/网络接口和目的地。</li></ul></li><li><strong>MTU 配置</strong>： <ul><li><strong>确保网络接口的 MTU 足够大以容纳 UDP 数据包，或者允许 IP 分片处理（尽管网闸连接器处理应用层分片，但避免 IP 分片对性能更好）。</strong></li></ul></li><li><strong>速率限制 (<a href="/zh-CN/flow_control"><code>send_delay_ms</code></a>)</strong>： <ul><li><strong>这是最关键的设置。</strong></li><li><strong>太低</strong>：你会溢出网闸接收缓冲区，导致丢包。</li><li><strong>太高</strong>：你会引入不必要的延迟并降低吞吐量。</li><li><strong>调优</strong>：从较高的值（例如 <code>10ms</code>）开始，逐渐降低，直到在<a href="/zh-CN/operations_guide#syslog">出口代理日志</a>中看到丢包，然后稍微回调。</li></ul></li><li><strong>缓冲区大小 (<a href="/zh-CN/software_architecture#无锁缓冲-bipbuffer"><code>bip_buffer_element_count</code></a>)</strong>： <ul><li><strong>如果预期源端会有突发流量，请增加此值。</strong></li></ul></li></ol><h2 id="监控" tabindex="-1">监控 <a class="header-anchor" href="#监控" aria-label="Permalink to “监控”">​</a></h2><p>网闸连接器的设计原则是“默认可观测 (observable by default)”。</p><h3 id="syslog" tabindex="-1">Syslog <a class="header-anchor" href="#syslog" aria-label="Permalink to “Syslog”">​</a></h3><p>网闸连接器发送结构化日志到<a href="/zh-CN/configuration_reference">配置</a>的 <code>toHostSysLog</code>, <code>toPortSysLog</code>。</p><ul><li><strong>Info</strong>: 启动事件、配置摘要。</li><li><strong>Warn</strong>: 可恢复的问题（例如，<a href="/zh-CN/configuration_reference#kafka-模式-protocolhandlerkafka">Kafka 连接丢失并正在重试</a>）。</li><li><strong>Error</strong>: 严重故障（例如，无效配置、线程 Panic）。</li></ul><h3 id="指标-statsd" tabindex="-1">指标 (StatsD) <a class="header-anchor" href="#指标-statsd" aria-label="Permalink to “指标 (StatsD)”">​</a></h3><p>网闸连接器将指标发送到任何兼容 <a href="https://github.com/statsd/statsd" target="_blank" rel="noreferrer">StatsD</a> 的收集器（Prometheus StatsD Exporter, Telegraf, Datadog）。</p><p><strong>关键指标：</strong></p><table tabindex="0"><thead><tr><th style="text-align:left;">指标名称</th><th style="text-align:left;">类型</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;"><code>ddc.ingress.packets_sent</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">发送到网闸的 UDP 数据包总数。</td></tr><tr><td style="text-align:left;"><code>ddc.ingress.bytes_sent</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">发送的总字节数。</td></tr><tr><td style="text-align:left;"><code>ddc.egress.packets_received</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">接收到的 UDP 数据包总数。</td></tr><tr><td style="text-align:left;"><code>ddc.egress.packet_loss</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;"><strong>严重</strong>。当检测到序列号缺口时增加。在健康系统中应为 0。</td></tr><tr><td style="text-align:left;"><code>ddc.dropped_packets</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">被<a href="/zh-CN/security_model#内容过滤与净化-dpi">过滤器</a>拒绝的数据包。</td></tr><tr><td style="text-align:left;"><code>ddc.buffer_full</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">如果环形缓冲区已满则增加（指示瓶颈）。</td></tr></tbody></table><h2 id="故障排查" tabindex="-1">故障排查 <a class="header-anchor" href="#故障排查" aria-label="Permalink to “故障排查”">​</a></h2><h3 id="场景-1-我看到出口代理端的-packet-loss-增加。" tabindex="-1">场景 1：&quot;我看到出口代理端的 <a href="/zh-CN/operations_guide#指标-statsd"><code>packet_loss</code></a> 增加。&quot; <a class="header-anchor" href="#场景-1-我看到出口代理端的-packet-loss-增加。" aria-label="Permalink to “场景 1：&quot;我看到出口代理端的 packet_loss 增加。&quot;”">​</a></h3><ul><li><strong>原因</strong>：<a href="/zh-CN/software_architecture#入口代理-ingress-proxy-发送端">入口代理</a>发送数据的速度超过了物理网闸或<a href="/zh-CN/software_architecture#出口代理-egress-proxy-接收端">出口代理</a>服务器的处理能力。</li><li><strong>修复</strong>：增加入口代理配置中的 <a href="/zh-CN/flow_control"><code>send_delay_ms</code></a>。即使是微小的增加（例如从 0ms 到 1ms）也能极大地稳定链路。</li></ul><h3 id="场景-2-数据没有到达目的地-但日志中没有错误。" tabindex="-1">场景 2：&quot;数据没有到达目的地，但日志中没有错误。&quot; <a class="header-anchor" href="#场景-2-数据没有到达目的地-但日志中没有错误。" aria-label="Permalink to “场景 2：&quot;数据没有到达目的地，但日志中没有错误。&quot;”">​</a></h3><ul><li><strong>原因</strong>：<a href="/zh-CN/security_model#内容过滤与净化-dpi">过滤器</a>可能正在静默丢弃数据（如果配置如此），或者出口代理正在接收数据但无法生产到下游。</li><li><strong>修复</strong>： <ol><li>检查 <a href="/zh-CN/operations_guide#指标-statsd"><code>ddc.dropped_packets</code></a> 指标。</li><li>在出口代理上设置 <a href="/zh-CN/configuration_reference"><code>logLevel = &quot;Debug&quot;</code></a> 以查看是否接收到 UDP 数据包。</li><li>验证出口代理 <code>protocolHandler</code> <a href="/zh-CN/configuration_reference#核心协议配置-protocolhandler">配置（正确的 Kafka topic/host）</a>。</li></ol></li></ul><h3 id="场景-3-高延迟。" tabindex="-1">场景 3：&quot;高延迟。&quot; <a class="header-anchor" href="#场景-3-高延迟。" aria-label="Permalink to “场景 3：&quot;高延迟。&quot;”">​</a></h3><ul><li><strong>原因</strong>：<a href="/zh-CN/flow_control"><code>send_delay_ms</code></a> 过大或缓冲区过大。</li><li><strong>修复</strong>：在不导致丢包的前提下尽可能降低 <a href="/zh-CN/flow_control"><code>send_delay_ms</code></a>。减小 <a href="/zh-CN/software_architecture#无锁缓冲-bipbuffer"><code>bip_buffer_element_count</code></a> 以更频繁地处理较小的批次。</li></ul><h3 id="场景-4-kafka-消费者组不断重平衡-rebalancing-。" tabindex="-1">场景 4：&quot;<a href="/zh-CN/deployment_topologies#kafka-consumer-group-failover-mode-active-active-sharding">Kafka 消费者组不断重平衡 (Rebalancing)</a>。&quot; <a class="header-anchor" href="#场景-4-kafka-消费者组不断重平衡-rebalancing-。" aria-label="Permalink to “场景 4：&quot;Kafka 消费者组不断重平衡 (Rebalancing)。&quot;”">​</a></h3><ul><li><strong>原因</strong>：处理耗时太长，导致 Kafka 认为消费者超时。</li><li><strong>修复</strong>：在<a href="/zh-CN/configuration_reference#核心协议配置-protocolhandler">协议处理器配置</a>中减小 <code>maxBytesPerPartition</code> 以获取更小的数据批次。</li></ul>',23)])])}const u=e(l,[["render",s]]);export{f as __pageData,u as default};
