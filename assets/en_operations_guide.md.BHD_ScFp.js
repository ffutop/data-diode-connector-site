import{_ as t,c as o,o as r,a6 as a}from"./chunks/framework.Cpr3xyXy.js";const u=JSON.parse('{"title":"DDC Operations Guide - Deployment, Monitoring & Troubleshooting","description":"Practical operations guide for Data Diode Connector (DDC). Includes pre-flight checklist, monitoring via StatsD metrics, Syslog configuration, and troubleshooting common issues like packet loss.","frontmatter":{"title":"DDC Operations Guide - Deployment, Monitoring & Troubleshooting","description":"Practical operations guide for Data Diode Connector (DDC). Includes pre-flight checklist, monitoring via StatsD metrics, Syslog configuration, and troubleshooting common issues like packet loss.","head":[["meta",{"name":"keywords","content":"DDC Operations, Production Deployment, Monitoring, Troubleshooting, StatsD Metrics, Packet Loss, Kafka Rebalancing"}]],"seo":{"proficiencyLevel":"Expert","keywords":["Operations Guide","Monitoring","Troubleshooting","Data Diode","Kafka Operations","Metrics"]}},"headers":[],"relativePath":"en/operations_guide.md","filePath":"en/operations_guide.md","lastUpdated":1764595667000}'),n={name:"en/operations_guide.md"};function i(s,e,l,c,d,g){return r(),o("div",null,[...e[0]||(e[0]=[a('<h1 id="operations-guide" tabindex="-1">Operations Guide <a class="header-anchor" href="#operations-guide" aria-label="Permalink to “Operations Guide”">​</a></h1><p>This document provides guidelines for <strong>deploying, monitoring, and troubleshooting</strong> the Data Diode Connector (DDC) in a production environment.</p><h2 id="deployment-checklist" tabindex="-1">Deployment Checklist <a class="header-anchor" href="#deployment-checklist" aria-label="Permalink to “Deployment Checklist”">​</a></h2><p>Before going live, ensure the following:</p><ol><li><strong>Network Reachability</strong>: <ul><li><strong>Ingress</strong>: Can reach the Source (e.g., Kafka) and the Diode Hardware/Network Interface.</li><li><strong>Egress</strong>: Can reach the Diode Hardware/Network Interface and the Destination.</li></ul></li><li><strong>MTU Configuration</strong>: <ul><li><strong>Ingress</strong>: Ensure the network interface MTU is large enough for the UDP packets, or let IP fragmentation handle it (though DDC handles application-layer fragmentation, avoiding IP fragmentation is better for performance).</li></ul></li><li><strong>Rate Limiting (<a href="/en/flow_control"><code>send_delay_ms</code></a>)</strong>: <ul><li><strong>This is the most critical setting.</strong></li><li><strong>Too Low</strong>: You will overflow the diode receiver buffer, causing packet loss.</li><li><strong>Too High</strong>: You will introduce unnecessary latency and reduce throughput.</li><li><strong>Tuning</strong>: Start high (e.g., <code>10ms</code>) and decrease until you see packet loss in the <a href="/en/operations_guide#syslog">Egress logs</a>, then back off slightly.</li></ul></li><li><strong>Buffer Sizing (<a href="/en/software_architecture#lock-free-buffering-bipbuffer"><code>bip_buffer_element_count</code></a>)</strong>: <ul><li><strong>Increase this if you expect bursty traffic from the source.</strong></li></ul></li></ol><h2 id="monitoring" tabindex="-1">Monitoring <a class="header-anchor" href="#monitoring" aria-label="Permalink to “Monitoring”">​</a></h2><p>DDC is designed to be &quot;observable by default&quot;.</p><h3 id="syslog" tabindex="-1">Syslog <a class="header-anchor" href="#syslog" aria-label="Permalink to “Syslog”">​</a></h3><p>DDC sends structured logs to the <a href="/en/configuration_reference">configured</a> <code>to_host_syslog</code> and <code>to_port_syslog</code>.</p><ul><li><strong>Info</strong>: Startup events, configuration summaries.</li><li><strong>Warn</strong>: Recoverable issues (e.g., <a href="/en/configuration_reference#kafka-mode-protocolhandler-kafka">Kafka connection lost and retrying</a>).</li><li><strong>Error</strong>: Critical failures (e.g., invalid config, thread panic).</li></ul><h3 id="metrics-statsd" tabindex="-1">Metrics (StatsD) <a class="header-anchor" href="#metrics-statsd" aria-label="Permalink to “Metrics (StatsD)”">​</a></h3><p>DDC emits metrics to any <a href="https://github.com/statsd/statsd" target="_blank" rel="noreferrer">StatsD</a>-compatible collector (Prometheus StatsD Exporter, Telegraf, Datadog).</p><p><strong>Key Metrics:</strong></p><table tabindex="0"><thead><tr><th style="text-align:left;">Metric Name</th><th style="text-align:left;">Type</th><th style="text-align:left;">Description</th></tr></thead><tbody><tr><td style="text-align:left;"><code>ddc.ingress.packets_sent</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">Total UDP packets sent to diode.</td></tr><tr><td style="text-align:left;"><code>ddc.ingress.bytes_sent</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">Total bytes sent.</td></tr><tr><td style="text-align:left;"><code>ddc.egress.packets_received</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">Total UDP packets received.</td></tr><tr><td style="text-align:left;"><code>ddc.egress.packet_loss</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;"><strong>Critical</strong>. Increments when a sequence gap is detected. Should be 0 in a healthy system.</td></tr><tr><td style="text-align:left;"><code>ddc.dropped_packets</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">Packets rejected by <a href="/en/security_model#content-filtering-and-sanitization">Filters</a>.</td></tr><tr><td style="text-align:left;"><code>ddc.buffer_full</code></td><td style="text-align:left;">Counter</td><td style="text-align:left;">Increments if the Ring Buffer is full (indicates bottlenecks).</td></tr></tbody></table><h2 id="troubleshooting" tabindex="-1">Troubleshooting <a class="header-anchor" href="#troubleshooting" aria-label="Permalink to “Troubleshooting”">​</a></h2><h3 id="scenario-1-i-see-packet-loss-increasing-on-the-egress-side" tabindex="-1">Scenario 1: &quot;I see <code>packet_loss</code> increasing on the Egress side.&quot; <a class="header-anchor" href="#scenario-1-i-see-packet-loss-increasing-on-the-egress-side" aria-label="Permalink to “Scenario 1: &quot;I see packet_loss increasing on the Egress side.&quot;”">​</a></h3><ul><li><strong>Cause</strong>: The <a href="/en/software_architecture#ingress-proxy-sender">Ingress</a> is sending data faster than the physical diode or the <a href="/en/software_architecture#egress-proxy-receiver">Egress</a> server can process it.</li><li><strong>Fix</strong>: Increase <code>transportUdpSend.sendDelayMs</code> in the <a href="/en/configuration_reference#transport-layer-send-configuration-transportudpsend">Ingress configuration</a>. Even a small increase (e.g., from 0ms to 1ms) can drastically stabilize the link.</li></ul><h3 id="scenario-2-data-is-not-arriving-at-the-destination-but-no-errors-in-logs" tabindex="-1">Scenario 2: &quot;Data is not arriving at the destination, but no errors in logs.&quot; <a class="header-anchor" href="#scenario-2-data-is-not-arriving-at-the-destination-but-no-errors-in-logs" aria-label="Permalink to “Scenario 2: &quot;Data is not arriving at the destination, but no errors in logs.&quot;”">​</a></h3><ul><li><strong>Cause</strong>: <a href="/en/security_model#content-filtering-and-sanitization">Filters</a> might be silently dropping data (if configured to do so), or the Egress is receiving data but failing to produce to the sink.</li><li><strong>Fix</strong>: <ol><li>Check <code>ddc.dropped_packets</code> metric.</li><li>Set <a href="/en/configuration_reference"><code>logLevel = &quot;Debug&quot;</code></a> on Egress to see if it&#39;s receiving UDP packets.</li><li>Verify the Egress <code>protocolHandler</code> <a href="/en/configuration_reference#core-protocol-configuration-protocolhandler-1">configuration</a> (correct Kafka topic/host).</li></ol></li></ul><h3 id="scenario-3-high-latency" tabindex="-1">Scenario 3: &quot;High Latency.&quot; <a class="header-anchor" href="#scenario-3-high-latency" aria-label="Permalink to “Scenario 3: &quot;High Latency.&quot;”">​</a></h3><ul><li><strong>Cause</strong>: Large <a href="/en/flow_control"><code>send_delay_ms</code></a> or extremely large buffers.</li><li><strong>Fix</strong>: Reduce <code>send_delay_ms</code> as much as possible without causing packet loss. Reduce <a href="/en/software_architecture#lock-free-buffering-bipbuffer"><code>bip_buffer_element_count</code></a> to process smaller batches more frequently.</li></ul><h3 id="scenario-4-kafka-consumer-group-rebalancing-constantly" tabindex="-1">Scenario 4: &quot;<a href="/en/deployment_topologies#kafka-consumer-group-failover-mode-active-active-sharding">Kafka Consumer Group rebalancing constantly</a>.&quot; <a class="header-anchor" href="#scenario-4-kafka-consumer-group-rebalancing-constantly" aria-label="Permalink to “Scenario 4: &quot;Kafka Consumer Group rebalancing constantly.&quot;”">​</a></h3><ul><li><strong>Cause</strong>: Processing is taking too long, causing Kafka to time out the consumer.</li><li><strong>Fix</strong>: Decrease <code>max_bytes_per_partition</code> in the <a href="/en/configuration_reference#kafka-mode-protocolhandlerkafka">Protocol Handler config</a> to fetch smaller batches.</li></ul>',23)])])}const f=t(n,[["render",i]]);export{u as __pageData,f as default};
